# Cracking the Code- an Anthropological overview of Artificial intelligence
Media Post for Anthropology 21

![Image](https://scet.berkeley.edu/wp-content/uploads/ethics-ai4-1024x768.png)

(Credits: SCET, UC Berkeley, 2019)

## Academic Integity

![Image](https://academicintegrity.ucsd.edu/_images/homepage-sample/ExcelWithIntegrity.jpg)
By reading or accessing this post, you are consenting to the academic integrity guidelines as set by the 
University of California San Diego Academic Senate as defined [here](https://senate.ucsd.edu/Operating-Procedures/Senate-Manual/Appendices/2). 
If any part of this post is found being used without prior approval of the authors and course instructor, it shall be reported to the
Academic Integirty Office at UCSD with disciplinary actions and consequences to follow.
For fair usage of this post, you may contact the authors or course instructor as given in the
acknowledgements below. 


## Acknowledgements

We would like to acknowledge the authors of this post and the instructors for this course, without whom this effort would not have been possible.
You can reach out to the course instructors and the authors for any questions pertaining to this article.

### Authors 

1. Aryamun Narayan Das- a3das@ucsd.edu A17050602
2. Aarav Singh Pruthi- Apruthi@ucsd.edu A16877338

### Instructors
1. Dr. Amy Kennemore- akennemore@ucsd.edu
2. Fatimah Kanth- mkanth@ucsd.edu
3. Annika Stone- abadamso@ucsd.edu
4. Loren Clark- lrclark@ucsd.edu
5. Michael Hillyer- mhillyer@ucsd.edu

## Introduction

The name of this blog post is “Cracking the Code," which is a pun on the fact that our article will revolve around the future of technology- AI and how anthropology will play a huge role in the future of AI development.

Being students in the fields of psychology and computer science, we, the authors, felt a personal connection to this topic. Human-Computer Interaction will be the key in the next phase of the 2020s and even further decades to come. The future is here, and we have the power of AI now. 

However, as the past has shown us, with the great power of AI comes the great responsibility of handling its potential pitfalls and biases.

Since our blog project is part of a class that fulfills such a requirement, we want to trace the past, present and future of AI to better understand how Anthropology will play a crucial role in AI ethics and maintaining accountability for automated machines and their respective stakeholders in the future.

Let us understand AI as a human computer interaction, and how anthropology can help mediate this human-computer interaction. 


## The computational side: Make way for the Prince A-I!

![Image](https://pbs.twimg.com/media/BwAbRXLIcAApl0K?format=png&name=medium) 

(Copyright: Walt Disney Company) 

no, not this handsome man

but rather

![Image](https://images.idgesg.net/images/article/2019/11/ai_artificial_intelligence_ml_machine_learning_vector_by_kohb_gettyimages_1146634284-100817775-large.jpg?auto=webp&quality=85,70)

this abstract object.



In November 2022, potentially the biggest development in human history took place, with the release of the GPT-3 chat bot, better known as ChatGPT.

With over a 100 million users (https://www.demandsage.com/chatgpt-statistics/)
and its ever growing prevalence in academia and daily life, we know it is one of the instances to indicate that AI is here to stay. With this in mind, we must reflect on what AI really means.

Artificial intelligence is basically the simulation of sentient tasks using computational algorithms, trained on certain datasets, much like human beings. Put in a more humorous manner, "Artificial Intelligence is the study of how to make computers do things which, at the moment, people do better." (Rich and Knight, Artificial Intelligence, 1991)

So, why do we say that people do what AI accomplishes better, despite AI models being run on supercomputers much more powerful than human brains?


## The reason: Who's behind this all?

Of course it is one species, who else could it be. The creator, the designer, the inventor of all things artificial,

![Image](https://img.buzzfeed.com/buzzfeed-static/static/2023-01/23/15/campaign_images/e470a0b884c3/83-times-michael-scott-from-the-office-made-us-bu-2-536-1674489171-13_dblbig.jpg)

humans.

Whatever humans falter in, is compounded and reflected by their creations. 

## How Anthropology helps
![Image](https://i.imgflip.com/7dtbbm.jpg)

Anthropology identifies the potential pitfalls and biases of the human side and mediates them, thereby minimising but not removing the biases that occur on the human side. 

### Influential Information- The mind games that is social media and online ads

![Image](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcREJgWAaXl5Vw4YufnisrCB4Y24RFUNawugVATVMkzjHhR9c8rJuNXlEM3EqgynZj4R0go&usqp=CAU)


Sourced from the Social Dilemma (https://www.netflix.com/title/81254224) and O’Neil, Cathy, 2016. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy

We live in an age in which we use algorithms and AI. But what if someone told you, that algorithms and AI weren't used *by you* but they were *using you*.

Scary, isn't it? 

![Image](https://cdn.shopify.com/s/files/1/1061/1924/products/Flushed_Face_Emoji_large.png?v=1571606037)


Well the unfortunate fact is, this is the truth in real life. Social media platforms and online ads, as proposed by the Social Dilemma netflix documentary, manipulate people psychologically through their version of the truth. The big tech companies push their narrative as a majority to your screen through their algorithms deliberately, and slowly fine tune your dopamine to certain topics, which causes you to pay more attention to those topics. It is a very subtle and slow change. Take for example, in real life. You watch a tiktok video where your favorite influencer is eating some food on a livestream. You watch this. Slowly over the next few days, tiktok puts food videos on your for you page and slowly enough you cannot stop thinking about food! Moreover, you will obviously get hungry thinking about food as ghrelin, your food androgen, gets triggered and you'll look to order something. Boom, all of a sudden you're thinking of ordering something and an online ad magically pops up for the latest offer on uber eats. You cannot resist temptation and swipe your card. They now have your attention and your money. Wasn't that the whole point of social media founders anyways? You eat here, they get your money and make their hefty corporate paycheck. Everyone goes home satisfied. Or do they?

What if person X with racist origins and biases founded a social media platform? Or got hired in the algorithms team? How about that. Would you be able to stop that person? Don't even bother answering that question, because by the time you think of stoping them, they have already taken control of your mindset and your head. You are just a sheep in the herd. Your right to free speech and your freedoms are surrendered to your phone. 

![Image](https://eightieskids.com/wp-content/uploads/2016/05/10-24.jpg)

This is why AI through social media is so dangerous. Remember, AI is a tool, but who uses the tool? Who creates it? Humans. If someone creates a product, remember that they can at anytime alter the product slightly to malfunction or perform the same thing differently. This is why we need AI ethics review bodies which are detached from the companies executive and technical bodies. Each and every employee's personal beliefs should be screened and they should undergo training to minimize their personal reflections in their product. Code should be reviewed thoroughly by experts and the models should be made public to the users. This makes sense and brings about accountability. 


### Problematic Programs- Weapons of math destruction

![Image](https://secondhome.io/wp-content/uploads/2019/11rnV4INKRyXRttuUw.jpg)
Sourced from O’Neil, Cathy, 2016. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy
and ProPublica, 2016 (https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm). 

Cathy O'Neil very correctly said, we are in an era of data science, the "Weapons of Math Destruction." Confirmed by Tim Lau's podcast and the 2016 ProPublica research article, the COMPAS dataset is one such example. Algorithms rely on data for their modification and data relies on algorithms for their preprocessing. This is one such case where both sides went horribly wrong.

Recidivism from the COMPAS dataset inference predicted that African American offenders were more likely to commmit a crime a second time after release, while in reality the Caucasian offenders did so. The dataset was heavily skewed towards African American offenders as it had more cases of reported crimes, an anomaly in itself considering many crimes committed by Caucasians isn't even reported in more conservative states. 

To add on, the magnitude of severity of the first crime was not weighed in, nor was the psychological evaluation or background of the offender. This goes to show that statistics are not fully reliable. There is very much a human factor involved in everything, whether it be the justice system or real life interactions, for which statistics cannot possibly account for, because mathematics does not work with emotions. Emotions and psychology are very much a chemical driven concept, which we really cannot predict, it depends on the background of people and their past experiences. Take nearly 8 billion people. There is not a single chance with the current level of computation and datasets that we can account for the feelings of every single human being on the planet and say, this person will be a repeat criminal and this person will not. 

With this being said, situations such as the above are labelled blindspots in data science, or WMDs. One blindspot can absolutely alienate an entire ethnic group if not carefully considered and brought to the attention of people. Anthropological research and not for profit organizations achieve this purpose through studying every such case and identifying blindspots, publishing them to the public eye and taking affirmative action against such anomalies.


![Image](https://s3.us-east-1.amazonaws.com/data-publica/assets/example/opener-b-crop-1200-675-00796e.jpg)


### Relational Biases-
In human relationships, prejudices can result in unjust treatment and incorrect conclusions. These prejudices might be intentional or unintentional, and they frequently depend on characteristics like gender, color, age, and appearance. They can take many forms, including discrimination, prejudice, and stereotyping. Unwelcome biases can result in missed opportunities, a lack of diversity, and poor performance, among other undesirable results (Summarised from Week 1, lectures 1 and 2, and [Week 10](https://padlet.com/akennemore/anth-21-module-5-resource-board-intergroup-trust-belonging-sz1f729ofg71rb6k/wish/2394763844). Distrust between groups and lack of intersectionality also plays a part in this. 

In order to overcome these biases, it is critical to be aware of them, actively attempt to lessen their impact, and pursue objectivity and justice in the decision-making process.

Discrimination is faced because of the projection of the majority opinion on minorities, majorities occupying positions of power, minorities unable to fight back and succumbing to their opinion because they do not have any support or knowledge to fight the discrimination. 

Anthropology brings non-intersecting groups together under a common umbrella, divided by the majority and united by their experiences. Through the sharing of perspectives and an anthropological breakdown of the discrimination faced, minorities as well as majorities can be well equipped to identify and tackle these issues. The ProPublica study on the COMPAS dataset is a prime example. It was a jolt and a shockwave across the tech industry, bringing a furore within tech minorities and keeping a check on majorities to act accountably. This interpersonal accountability is brought about by Anthropology, along with the unison of minority groups to fight against hatred as one. 


### Hiring Biases-

(https://hbr.org/2016/07/why-diversity-programs-fail)

Hiring biases are unintentional or intentional prejudices that have an impact on the recruiting decision-making process and cause candidates to be chosen based on criteria unrelated to their work performance or credentials. These prejudices can show themselves in different ways, depending on factors including gender, race, ethnicity, age, physical appearance, and educational background. Hiring biases can significantly affect the workplace's diversity and inclusivity as well as the business's overall success. To overcome recruiting biases, firms can employ measures such as blind resume screening, diversity training, and developing diverse hiring committees. 

To expand on the above, DEI training could be considered a solution, however, in practice, they are deemed ineffective. An anthropological overview shows that with interpersonal relationships, we do know the answers to the questions, but seem to be in a tutorial hell when it comes to implementing these solutions in real life. Companies use very negative sentiments with negative repercussions at present to curb relational biases. This creates a negative feedback loop which in turn causes employees to react negatively to the corporate structure, as DEI training is used as a punishment of sorts, creating a stigma against the whole concept. Encouraging the importance of the Business-Psychological factor of DEI, which deals with sentiments of classically discriminated groups and factors them into companies and algorithmic decision making is key to solving this problem. Anthropology puts forward these perspectives and sentiments of minority groups through its stories, and interestingly appreciates differences betweeen the general opinion and the minority opinion. The stigma against DEI can be removed through this positive reinforcement of creating better products and services for customers this way, while having thorough respect and attention to the minority stories and narratives. 

Another very human sentiment is vanity. If not ethics, human beings always succumb to the pressure of validation and vanity. The fear of not being socially acceptable and being shunned is a constant one. This human sentiment is driven to do positive things through anthropology. Anhtropological concepts and methodologies such as diversity camps, increased recruitment from minorities, exposure to minority surroundings, etc. have shown to drive up the reprsentation of minorities and a positive feeling around them. This means more minorities in the workplace and more people to interact with. People are motivated to be acceptible, which makes them accountable. It is this accountability which we need in the 21st century workplace, which is not possible without an anthropological intervention.

![Image](https://media.makeameme.org/created/vanity-vanity-all.jpg)


To conclude, anthropology serves as a screen for identifying changes to be made and keeps every stakeholder in the algorithmic decision making process accountable. With this accountability, we can ensure that AI is ethical and safe for all, moreover being accessible to everyone and accounting for every group's point of view, whether majority or minority. 

With that, we'd like to thank you for reading our post and bid you goodbye. If possible, please share this with your classmates and family members as we have worked tirelessly to bring this issue to the attention of the public and be of great support to us in our future endeavors.
